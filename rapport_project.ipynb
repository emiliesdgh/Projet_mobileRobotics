{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Basics of Mobile Robotics project<span class=\"tocSkip\"></span></h1>\n",
    "\n",
    "**Group 23 : Diana Bejan** (325029)**, Emilie Grandjean** (286734)**, Garance Boesinger** (310447)**, Juan Martín** (376659)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Table of contents**<a id='toc0_'></a>    \n",
    "1. [Introduction](#toc1_)    \n",
    "2. [General Setup](#toc2_)    \n",
    "2.1. [Project description](#toc2_1_)    \n",
    "2.2. [Environment Setup  GARANCE](#toc2_2_)    \n",
    "2.3. [Best Path Calculations KIKE](#toc2_3_)    \n",
    "2.4. [Motion Control DIANA](#toc2_4_)    \n",
    "2.5. [Obstacles avoidance](#toc2_5_)    \n",
    "3. [Required Components](#toc3_)    \n",
    "3.1. [Computer Vision GARANCE](#toc3_1_)    \n",
    "3.2. [Global Navigation KIKE](#toc3_2_)    \n",
    "3.3. [Motion Control DIANA](#toc3_3_)    \n",
    "3.4. [Local Navigation](#toc3_4_)    \n",
    "3.5. [Filtering](#toc3_5_)    \n",
    "4. [VIDEOS ? IMAGES ? LITTLE EXTRAS ?](#toc4_)    \n",
    "5. [Overall Project](#toc5_)    \n",
    "6. [Conclusion](#toc6_)    \n",
    "\n",
    "<!-- vscode-jupyter-toc-config\n",
    "\tnumbering=true\n",
    "\tanchor=true\n",
    "\tflat=true\n",
    "\tminLevel=1\n",
    "\tmaxLevel=6\n",
    "\t/vscode-jupyter-toc-config -->\n",
    "<!-- THIS CELL WILL BE REPLACED ON TOC UPDATE. DO NOT WRITE YOUR TEXT IN THIS CELL -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. <a id='toc1_'></a>[Introduction](#toc0_)\n",
    "\n",
    "As part of the Basics of Mobile Robotic class given by M. Mondada, we are asked to implement a project using the Thymio robot. This project involves the robot reaching a goal while moving in an environment filled with permanent obstacles. During it's path, some extra physical obstacles can be placed in its way. In such moments, the Thymio has to be able to avoid them and continue its route to the end point.\n",
    "\n",
    "This is then done using several concepts seen in class such as image processing and pattern detection with Computer Vision, the Motion Control using a controller, Global and Local Navigation of the Thymio and Filtering.\n",
    "\n",
    "In this report, we will talk about the different modules implemented and detail how they work to explain our overall functionnality of our project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. <a id='toc2_'></a>[General Setup](#toc0_)\n",
    "\n",
    "## 2.1. <a id='toc2_1_'></a>[Project description](#toc0_)\n",
    "\n",
    "1. **Create an environnment :** Our environment has to contain a set of obstacles that the Thymio avoids through *global navigation*. That is to say, the Thymio should avoid the obstacles without using the sensors to detect them.\n",
    "\n",
    "2. **Find the best path :** The obective is that the Thymio goes from an *arbitrary point* in the map to a *target* that can be placed <u>anywhere</u> in the environment.  These will be changed during the demo to see how the system performs.\n",
    "\n",
    "3. **Motion Control & Position estimation:** We will *control* the robot to help it move along the path. This requires an accurate estimate of the position of the robot which we will have to obtain through *bayesian filtering*.\n",
    "   \n",
    "4. **Avoid Obstacles :** While navigating, the Thymio will have to use *local navigation* to avoid *physical obstacals* that can be put in its path <u>at any point in time</u>. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. <a id='toc2_2_'></a>[Environment Setup  GARANCE](#toc0_)\n",
    "\n",
    "environment : the static obstacles have to be in 2D (it will be easier to detect with the camera than if it’s in 3D because the shadows are hard to detect and so it’s better to do it that way (heard an assistant say it))\n",
    "\n",
    "quick explication on what our setup looks like, the use of the colors with pitcures\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3. <a id='toc2_3_'></a>[Best Path Calculations KIKE](#toc0_)\n",
    "\n",
    "short explication on what method used and why and how and quickly mention that it uses the info send by the CV picked up by the environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4. <a id='toc2_4_'></a>[Motion Control](#toc0_)\n",
    "\n",
    "In motion control, we decided to only set speeds. The speeds are chosen with respect to the distance between the current position and the next point on the path and the angle between the current angle and the angle we’d like to have. The Kálmán filter and the global navigation give these values. The motion is a continuous exchange between turning and advancing phases.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5. <a id='toc2_5_'></a>[Obstacles avoidance](#toc0_)\n",
    "\n",
    "For the obstacle avoidance section, we decided to use 3D physical obstacles that cannot be detected by the camera. This will push the use of the Thymio's sensors to detect these obstacles. Since they can be put at anytime anywhere in the robot's path, using **Local Navigation** will allow to avoid them and once the obstacle avoided, the robot need to go back to following it's given path."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. <a id='toc3_'></a>[Required Components](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1. <a id='toc3_1_'></a>[Computer Vision GARANCE](#toc0_)\n",
    "\n",
    "use of the camera (placed above the environment) —> locate the environment (edges etc.), the static (2D) obstacles and the thymio\n",
    "\t—> only do image processing (quickly saw in an exercise session) and use the given file explaining what to do, how to extract and process the image data.\n",
    "\t—> use AR tags : the camera can practically do everything on it’s own\n",
    "\t—> ! the camera does not use the same parameters for macs and windows => the one doing this will be the only one\n",
    "\n",
    "\n",
    "details explications : step by step, accompagné by images and pieces of code of\n",
    "\n",
    "on how it's done, what  calculations used, what variables used, the form of the vision file(is it a class, just a fct ? why ?)\n",
    "\n",
    "++ add images to go with the description to illustrate the explications\n",
    "\n",
    "detail explications on the differents functions called and what their inputs are and what their outputs are (can be done in un tableau for example), explain their use and the goal of using them and when they are used (like it what function are they called etc )\n",
    "\n",
    "\n",
    "separation in several parts ? the computation of the position of thymio? the environment ? the obstacles ? the goal ?\n",
    "\n",
    "++ sources\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2. <a id='toc3_2_'></a>[Global Navigation KIKE](#toc0_)\n",
    "\n",
    "use the location of the static obstacles given by the vision step and find the optimal path the thymio has to follow to reach the goal (no movement, just find the best trajectory)\n",
    "\t—> use of existing libraries !\n",
    "\n",
    "  \n",
    "details explications : step by step, accompagné by images(?)--> video showing the path followed ? and pieces of code of\n",
    "\n",
    "on how it's done, what  calculations used, what variables used, the form of the vision file(is it a class, just a fct ? why ?)\n",
    "\n",
    "++ add images or videos to go with the description to illustrate the explications\n",
    "\n",
    "detail explications on the differents functions called and what their inputs are and what their outputs are (can be done in un tableau for example), explain their use and the goal of using them and when they are used (like it what function are they called etc )\n",
    "\n",
    "\n",
    "separation in several parts ? the computation of the position of thymio? the environment ? the obstacles ? the goal ? how was the algo written and used ? what does it send to who (MC) \n",
    "--> the implementation, the algorithm, ...\n",
    "\n",
    "is it optimal ? yes ok, no, why ? \n",
    "\n",
    "++ sources\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3. <a id='toc3_3_'></a>[Motion Control DIANA](#toc0_)\n",
    "\n",
    "<u>**Idea**</u>\n",
    "\n",
    "This module of our project is used to give the wheels the necessary speeds to make the right movements. Three functions are present : the PID controller **PID_control()**, the turning function **turn()**, and the forward motion function **go_to_next_point()**. We switch between two phases while going from one point to the next. First, the turning phase where we use **turn()** to get in the angle that allows the robot to only move forward to reach the next point. Second, the advancing phase, which advences to the next point. \n",
    "\n",
    "The module is only called when there is no obstacle detected by the robot's proximity sensors. The functions work in a point-to-point and moment-to-moment fashion. This means that the angles taken into account are the current angle given by the Kálmán filter as well as the goal angle calculated between the first and second points of the path. The speeds are calculated for the distance between the two aforementioned points rather than from the current position to the final goal position.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. PID Controller**\n",
    "\n",
    "The code has been inspired by the PI controller implemented in the course MICRO-315 given by Prof. Mondada. The PID controller is used for angle correction and is an integral part of both the turning and the forward motion phases. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Funtion | Input | Output |\n",
    "|:------|:------|:------|\n",
    "|   ` def fonction()`  | input input input | output output output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Indeed, we look at the actual angle, *current_angle*, given by the filter,  and the goal angle of the robot, *robot.goal_angle* and using the difference between the two, *error, the integral error, *robot.int_error*, the previous error, *robot.prev_error*, as well as the time difference between two calls of the PID controller to calculate an optimal speed for attaining the desired angle. \n",
    "\n",
    "**Add some explenation about how get the time difference**\n",
    "\n",
    "While in **turn()** it is the only calculation of speed, in **go_to_next_point()** it adds a rotational speed to a forward speed already calculated. The coefficients KP, KI and KD have been experimentally chosen during testing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "**2. Turning function**\n",
    "\n",
    "The first function the program goes through between two points is the turning function, turn. This function takes as numerical inputs the current angle, given by the filter,  and the goal angle of the robot, as calculated from the path in the Thymio class. The PID controller is called for the calculation of the speed that is then passed to the robot by the functions setSpeedLeft/setSpeedRight found in the class Thymio. A helper variable, goal_reached_t is used to signal whether the turning phase has ended and the forward motion can start.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Funtion | Input | Output |\n",
    "|:------|:------|:------|\n",
    "|   ` def fonction()`  | input input input | output output output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Forward motion function**\n",
    "\n",
    "Once the turning phase is done, as signalled by *goal_reached_t*, the advancing phase can be accessed. This function calculates and sends speeds similar to the turning phase. The speed is proportionally controlled to slow down and smoothly reach the next point. The coefficient K has also been experimentally chosen during testing. We use the PID controller to add a rotational speed in order to correct the angle and so to make sure that the robot stays on track.\n",
    "\n",
    "Once the goal is reached, the second point in the path is discarded (the first one in the current position as given by the camera) and a new goal angle is calculated using the **setAngle()** function found in the file *classes.py* . A helper variable goal_reached_f is used to signal that the motion phase has ended and a new turning motion can begin."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Funtion | Input | Output |\n",
    "|:------|:------|:------|\n",
    "|   ` def fonction()`  | input input input | output output output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ConnectionRefusedError",
     "evalue": "[Errno 61] Connection refused",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mConnectionRefusedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m/Users/emscomputer/Projet_mobileRobotics/Projet_mobileRobotics/rapport_project.ipynb Cell 20\u001b[0m line \u001b[0;36m6\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/emscomputer/Projet_mobileRobotics/Projet_mobileRobotics/rapport_project.ipynb#Y112sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmotion_control\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/emscomputer/Projet_mobileRobotics/Projet_mobileRobotics/rapport_project.ipynb#Y112sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mclasses\u001b[39;00m \u001b[39mimport\u001b[39;00m Thymio\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/emscomputer/Projet_mobileRobotics/Projet_mobileRobotics/rapport_project.ipynb#Y112sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m client \u001b[39m=\u001b[39m ClientAsync()\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/emscomputer/Projet_mobileRobotics/Projet_mobileRobotics/rapport_project.ipynb#Y112sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m node \u001b[39m=\u001b[39m \u001b[39mawait\u001b[39;00m client\u001b[39m.\u001b[39mwait_for_node()\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/emscomputer/Projet_mobileRobotics/Projet_mobileRobotics/rapport_project.ipynb#Y112sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mawait\u001b[39;00m node\u001b[39m.\u001b[39mlock()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tdmclient/clientasync.py:42\u001b[0m, in \u001b[0;36mClientAsync.__init__\u001b[0;34m(self, node_class, **kwargs)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, node_class\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m---> 42\u001b[0m     \u001b[39msuper\u001b[39;49m(ClientAsync, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     43\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnode_class \u001b[39m=\u001b[39m node_class \u001b[39mor\u001b[39;00m tdmclient\u001b[39m.\u001b[39mClientAsyncCacheNode\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tdmclient/client.py:98\u001b[0m, in \u001b[0;36mClient.__init__\u001b[0;34m(self, zeroconf, zeroconf_all, tdm_ws, tdm_addr, tdm_port, tdm_transport, password, **kwargs)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdebug \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtdm_transport \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     97\u001b[0m         \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mTDM \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtdm_addr\u001b[39m}\u001b[39;00m\u001b[39m:\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtdm_port\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> 98\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconnect()\n\u001b[1;32m     99\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msend_handshake(password)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tdmclient/client.py:112\u001b[0m, in \u001b[0;36mClient.connect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtdm \u001b[39m=\u001b[39m TDMConnectionWS(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtdm_addr, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtdm_ws_port)\n\u001b[1;32m    111\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 112\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtdm \u001b[39m=\u001b[39m TDMConnection(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtdm_addr, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtdm_port)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tdmclient/tcp.py:104\u001b[0m, in \u001b[0;36mTDMConnection.__init__\u001b[0;34m(self, host, port, debug)\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mwrite\u001b[39m(\u001b[39mself\u001b[39m, b):\n\u001b[1;32m    102\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msocket\u001b[39m.\u001b[39msendall(b)\n\u001b[0;32m--> 104\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mio \u001b[39m=\u001b[39m TCPClientIO(host, port)\n\u001b[1;32m    105\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdebug \u001b[39m=\u001b[39m debug\n\u001b[1;32m    106\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtimeout \u001b[39m=\u001b[39m \u001b[39m3\u001b[39m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tdmclient/tcp.py:96\u001b[0m, in \u001b[0;36mTDMConnection.__init__.<locals>.TCPClientIO.__init__\u001b[0;34m(self, host, port)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, host, port):\n\u001b[1;32m     95\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msocket \u001b[39m=\u001b[39m socket\u001b[39m.\u001b[39msocket(socket\u001b[39m.\u001b[39mAF_INET, socket\u001b[39m.\u001b[39mSOCK_STREAM)\n\u001b[0;32m---> 96\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msocket\u001b[39m.\u001b[39;49mconnect((host, port))\n",
      "\u001b[0;31mConnectionRefusedError\u001b[0m: [Errno 61] Connection refused"
     ]
    }
   ],
   "source": [
    "\"Add code to show how this this works between two points\"\n",
    "from tdmclient import ClientAsync\n",
    "import motion_control\n",
    "from classes import Thymio\n",
    "\n",
    "client = ClientAsync()\n",
    "node = await client.wait_for_node()\n",
    "await node.lock()\n",
    "await node.wait_for_variables()\n",
    "\n",
    "Thym=Thymio()\n",
    "Thym.path=[[0,10],[2,50]]\n",
    "Thym.pos_X=Thym.path[0][0]\n",
    "Thym.pos_Y=Thym.path[0][1]\n",
    "Thym.setAngle()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Thym.goal_angle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Management of the reaching of the final goal position**\n",
    "\n",
    "When the length of the path is down to one, the goal position has been reached and the work is done. We see this in the code for **go_to_next_point()**, where there is a condition that skips the function if the path length is too short. The speeds are set to 0 as a advancing phase has been completed, and no new angle is calculated nor is the path changed anymore, as only the current position is left. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def go_to_next_point(current_angle, current_position, obstacle, robot, node): \n",
    "    if len(robot.path) > 1:\n",
    "        \"code\"\n",
    "    else:   # Advancing phase in completed when close enough to the desired point\n",
    "        robot.goal_reached_f = True\n",
    "        robot.goal_reached_t = False\n",
    "        robot.prev_error = 0\n",
    "        robot.int_error = 0\n",
    "        robot.prev_time = 0\n",
    "        robot.setSpeedRight(0,node)\n",
    "        robot.setSpeedLeft(0,node)\n",
    "        robot.path.pop(1)   # Path shortened\n",
    "\n",
    "    if len(robot.path) > 1:\n",
    "        robot.setAngle()    # Angle changed with respect to the new goal\n",
    "                \n",
    "    else:\n",
    "        pass    # Function skipped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As seen in the code above, the condition has to be introduced in the advancing phase completion as the* *robot.setAngle()** function takes the shortened path as an input before it is taken into account by the whole function in a future call."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4. <a id='toc3_4_'></a>[Local Navigation](#toc0_)\n",
    "\n",
    "<u>**Idea**</u>\n",
    "\n",
    "The **Local Navigation** module is inspired by the exercise session *Week 3 - Artificial Neural Networks* paragraph 5. The local_navigation.py file contains 3 functions, two verification functions and the actual function that makes the Thymio avoid obstacles which would be placed in its path."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Testing the presence of an obstacle**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Funtion | Input | Output |\n",
    "|:------|:------|:------|\n",
    "|   ` def test_saw_osb(Thymio, node, obs_threshold): `  | The class *Thymio* from the file *classes.py* to be able to modify the booleen variable **obs_avoided**, the threashold value to which the sensors detect the obstacle is close enough | returns *True* or *False* depending on if there's an obstacle or not, set the booleen variable **obs_avoided** to *False* if an obstacle is detected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function **test_saw_obs()** is actually practically the same as *test_saw_wall* from the exercise but without the use of the *verbose* booleen and instead, when an obstacle is detected, the function sets a global booleen variable called **obs_avoided** to *false*. This variable is used in the Local obstacle avoidance function so that it stays in the loop until the obstacle is fully contoured.\n",
    "\n",
    "This function take in input the obstacle threashold (*obs_threshold*) that is set in the 3rd function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_saw_osb(Thymio, node, obs_threshold) :\n",
    "\n",
    "    '''This function verrifies if one of the proximity horiontal sensors\n",
    "        sees and obstacle within the giving threashold.'''\n",
    "    \n",
    "    if any([x>obs_threshold for x in node['prox.horizontal'][:-2]]):\n",
    "\n",
    "        Thymio.obs_avoided = False  # Booleen to state when the obstacle has been avoided or not\n",
    "        return True\n",
    "\n",
    "    return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Testing in what direction to contourn**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Function | Input | Output |\n",
    "|:------|:------|:------|\n",
    "|   `def clockwise(node):`  |  | returns *True* or *False* depending on if the obstacle is most on the right or the left of the robot and let the next function know weather to contourn clockwise or counterclockwise\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our obstacles are cylinders that the Thymio contourns. Therefore, we want to know whether to contourn it clockwise or counterclockwise. This depends on if the obstacle is more on the right or the left of the robot when it get's in its path. The function **clockwise()** tests which sensor between the sensor <span style='color: red;'>[1]</span> (left) and the sensor <span style='color: red;'>[3]</span> (right) is currently detecting the obstacle. If in fact the sensor on the left ([1]) has a higher value than the other one, the functionn returns *true*, otherwise it returns *false*. This function is only called in the Local obstacle avoidance function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clockwise(node) :\n",
    "\n",
    "    '''This function verrifies if the obstacle to avoid is more on its right or left,\n",
    "        therefore, the Thymio will contourn it accordingly.'''\n",
    "\n",
    "    prox = list(node[\"prox.horizontal\"]) + [0]\n",
    "    if prox[1] > prox[3] :\n",
    "        return True\n",
    "    \n",
    "    return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Local obstacle avoidance**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Function| Input | Output |\n",
    "|:------|:------|:------|\n",
    "|   `def obstacle_avoidance(Thymio, node, client, motor_speed=100, obs_threshold=500):`  | The class *Thymio* from the file *classes.py* to be able to modify the booleen variable **obs_avoided**, the motor speed for the movement of the wheels, set to 100, the threashold value to which the sensors detect the obstacle set to 500 | no real output, but modification of **obs_avoided** booleen when the obstacle is avoided\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function **obstacle_avoidance()** can be devided in two states : the '*turning*' and the '*contourning*'.\n",
    "\n",
    "As soon the function is called, it starts by setting two variables : **clockwise_true** to *false* and **prev_state** to \"*turning*\". Then, since the 1st function (**test_saw_osb()**) has been called, the booleen **obs_avoided** is *false* and so we enter a while loop. \n",
    "\n",
    "This is when we enter the state of '*turning*' where we test, thanks to the 2nd function (**clockwise()**) if the Thymio will have to contourn on the left or on the right of the obstacle. If the robot has to turn clockwise, the booleen **clockwise_true** is set to *true*, otherwise, it stays to *false*. The set '*turning*' makes the Thymio rotate on itself so its not facing the obstacle anymore. Once this is done, the state is set to '*contourning*'.\n",
    "\n",
    "Still in the while loop, we enter the state of '*contourning*' where, depending on the value of te booleen **clockwise_true**, the Thymio will move in an arc circle around the obstacle and then back to the '*turning*' state, it rotates on itself again to be back facing in the right direction to allow going on with the Motion Control.\n",
    "\n",
    "At the end of the '*contourning*' state, the booleen variable **obs_avoided** is set to *true*, meaning that the Thymio has finised avoiding the obstacle and that the Motion Control can pick up again.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obstacle_avoidance(Thymio, node, client, motor_speed=100, obs_threshold=500): #, clockwise = False):\n",
    "    \"\"\"\n",
    "    Wall following behaviour of the FSM\n",
    "    param motor_speed: the Thymio's motor speed\n",
    "    param wall_threshold: threshold starting which it is considered that the sensor saw a wall\n",
    "    param white_threshold: threshold starting which it is considered that the ground sensor saw white\n",
    "    param verbose: whether to print status messages or not\n",
    "    \"\"\"\n",
    "\n",
    "    clockwise_true = False  # Booleen to state if the Thymio has to contourn on the left or right\n",
    " \n",
    "    prev_state = \"turning\" # Stated of movement of the Thymio\n",
    "    \n",
    "    while not Thymio.obs_avoided :     # As long as the obstacle isn't avoided, stay in the while loop \n",
    "    \n",
    "        if test_saw_osb(Thymio, node, obs_threshold) :\n",
    "            \n",
    "            if prev_state == \"turning\": # little rotation on it's own to then do the contourning\n",
    "  \n",
    "                if clockwise(node) :\n",
    "                    \n",
    "                    Thymio.setSpeedLeft(motor_speed, node)\n",
    "                    Thymio.setSpeedRight(-motor_speed, node)\n",
    "\n",
    "                    clockwise_true = True   # Thymio needs to contourn the obstacle clockwise\n",
    "\n",
    "                else :\n",
    "                    # Thymio needs to contourn the obstacle counterclockwise\n",
    "                    \n",
    "                    Thymio.setSpeedLeft(-motor_speed, node)\n",
    "                    Thymio.setSpeedRight(motor_speed, node)\n",
    "                    \n",
    "                prev_state = \"contourning\" # Change the state so the Thymio countourns the obstacle fully\n",
    "        \n",
    "        else:\n",
    "            if prev_state == \"contourning\": \n",
    "\n",
    "                if clockwise_true :\n",
    "\n",
    "                    Thymio.setSpeedLeft(motor_speed-40, node)\n",
    "                    Thymio.setSpeedRight(motor_speed, node)\n",
    "\n",
    "                    prev_state = \"turning\"\n",
    "\n",
    "                    aw(client.sleep(18))\n",
    "\n",
    "                    Thymio.setSpeedLeft(motor_speed, node)\n",
    "                    Thymio.setSpeedRight(-motor_speed, node)\n",
    "\n",
    "                    aw(client.sleep(2))\n",
    "\n",
    "                    Thymio.obs_avoided = True  # obstacle has been avoided, change the state booleen\n",
    "                    \n",
    "                else :\n",
    "\n",
    "                    Thymio.setSpeedLeft(motor_speed,node)\n",
    "                    Thymio.setSpeedRight(motor_speed-40,node)\n",
    "\n",
    "                    prev_state=\"turning\"\n",
    "\n",
    "                    aw(client.sleep(18))\n",
    "\n",
    "                    Thymio.setSpeedLeft(-motor_speed,node)\n",
    "                    Thymio.setSpeedRight(motor_speed,node)\n",
    "\n",
    "                    aw(client.sleep(2))\n",
    "\n",
    "                    Thymio.obs_avoided = True  # obstacle has been avoided, change the state booleen\n",
    "\n",
    "        aw(client.sleep(0.1)) #otherwise, variables would not be updated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.5. <a id='toc3_5_'></a>[Filtering](#toc0_)\n",
    "\n",
    "<u>**Idea**</u>\n",
    "\n",
    "The necessity of a filter comes from the fact that the Thymio is not a perfect robot. This means that the robot may not always act as expected. Therefore, we implement a filter which uses two sources of informations (the position of the Thymio given by the camera and the odometry based on internal measurements specific to the Thymio). The overall goal of the filter is to take into consideration possible imperfections of the robot and predict its actual real position. The **Filtering** module is inspired by the exercise session *Week 8 - Kalman Filter* paragraph 7.1. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Kalman Filter and sensors used**\n",
    "\n",
    "<u>Filter</u>\n",
    "\n",
    "The issue relies in the incertainty of the exact position of the robot and therefore the accuracy to perform the intended actions. We depend on two sources of information to obtain the position of the Thymio. Hence, from the many possible filters available, we decided to implement a classic Kalman Filter. \n",
    "\n",
    "This filter acts as an estimator for the position and the speed of the Thymio when provided with several source of information. Since the wheels don't have encoders, we use the measurements of the speed and the position provided by the Computer Vision. In addition, with the present noise being Gaussian noise, Kalman filters are a simpler representation of a distribution with the variables : mean and variance, and can be assumed these filters are Gaussian.\n",
    "\n",
    "We also decided to use a classic Kalman Filter rather than a EKF (Extended Kalman Filter) because, even though our system is non linear, we linearize it before applying the Kalman. Therefore, using a classic Kalman is sufficient.\n",
    "\n",
    "The **Filtering** module is inspired by the exercise session *Week 8 - Kalman Filter* paragraph 7.1. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "<u>Sensors</u>\n",
    "\n",
    "Like mentioned above, since the Kalman Filter is Gaussian, it can be used to compare different sensor measurements : \n",
    "\n",
    "- Camera : from Computer Vision, the information measured is the Thymio's position - coordinates ($x$, $y$) and angle ($\\theta$)\n",
    "- Odometry : using the robot's speed sensors, the informations measured are the wheels speed ($\\dot{x} = v_{x}$, $\\dot{y} = v_{y}$) and the angular velocity ($\\dot{\\theta}$)\n",
    "\n",
    "By using serveral source of measurements, we can allow the filter to function even if the camera is suddently unavailable and have our Motion Control still operate correctly.\n",
    "\n",
    "We will see later on, but it is trough the **Odometry** that we linearize our system so that we can perform a classic KF rather than an EKF.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Code**\n",
    "\n",
    "<u>States</u>\n",
    "\n",
    "The states we consider are the Thymio's position and its velocities. The best case senario is when we have the Computer Vison and the Odometry functionning. \n",
    "\n",
    "$$\n",
    "States \n",
    "= \n",
    "%\\begin{gather}\n",
    " \\begin{bmatrix}\n",
    "           x_{k} \\\\\n",
    "           \\dot{x_{k}}\\\\\n",
    "           y_{k} \\\\\n",
    "           \\dot{y_{k}}\\\\\n",
    "           \\theta_{k} \\\\\n",
    "           \\dot{\\theta_{k}}\n",
    " \\end{bmatrix}\n",
    "=\n",
    " \\begin{bmatrix}\n",
    "           x_{k} \\\\\n",
    "           v_{x_{k}}\\\\\n",
    "           y_{k} \\\\\n",
    "           v_{y_{k}}\\\\\n",
    "           \\theta_{k} \\\\\n",
    "           v_{\\theta_{k}}\n",
    " \\end{bmatrix}\n",
    "%\\end{gather}\n",
    "$$\n",
    "\n",
    "$$x_{t+1} = Ax_{t} + w_{t}$$\n",
    "$$y_{t} = Hx_{t} + v_{t}$$\n",
    "\n",
    "Where, $x_{k}$ is the state of the system at sample $k$, $\\mathbf{A}$ is the matrix defining how the system evolves, $w_{k}$ is the state stochastic perturbation with covariance matrix $\\mathbf{Q}$, $y_{k}$ is the measurement related to the state by the matrix $\\mathbf{H}$ and $v_{k}$ is the measurement noise with covariance matrix $\\mathbf{R}$.\n",
    "\n",
    "The actual measurements $y_{k}$ depend on if we have Camera Vision as well as Odometry or not. On the other hand, we do not use values for known inputs $u_{k}$ and the impacting matrix $\\mathbf{B}$ because we assume that the Thymio's speed is considered as a state and not an input. In other words, we do a sort of approximation of the real system to simplify the model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>Matrices</u>\n",
    "\n",
    "\n",
    "- Therefore, we start by computing the sensors covariance matrix $\\mathbf{R}$ :\n",
    "\n",
    "$$\n",
    "\\mathbf{R}\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "r_{11} & 0 & 0 & 0 & 0 & 0 \\\\\n",
    "0 & r_{22} & 0 & 0 & 0 & 0 \\\\\n",
    "0 & 0 & r_{33} & 0 & 0 & 0 \\\\\n",
    "0 & 0 & 0 & r_{44} & 0 & 0 \\\\\n",
    "0 & 0 & 0 & 0 & r_{55} & 0 \\\\\n",
    "0 & 0 & 0 & 0 & 0 & r_{66} \\\\\n",
    "\n",
    "\\end{bmatrix}\\\\\n",
    "$$\n",
    "\n",
    "$\n",
    "r_{11} = q_{cam,x} = 7.73 \\quad\n",
    "r_{22} = q_{\\dot{x}} = 6.48\\quad\n",
    "r_{33} = q_{cam,y} = 7.73\\quad\n",
    "r_{44} = q_{\\dot{y}} = 6.48\\quad\n",
    "r_{55} = q_{cam,\\theta} = 0.0049\\quad\n",
    "r_{66} = q_{\\dot{\\theta}} = 0.615\\quad\n",
    "$\n",
    "\n",
    "\n",
    "When there is no vision, the matrix looks like : \n",
    "\n",
    "$$\n",
    "\\mathbf{R}\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "r_{22} & 0 & 0 \\\\\n",
    "0 & r_{44} & 0 \\\\\n",
    "0 & 0 & r_{66} \\\\\n",
    "\n",
    "\\end{bmatrix}\\\\\n",
    "$$\n",
    "\n",
    "with the same values for $r_{22}$, $r_{44}$ and $r_{66}$\n",
    "\n",
    "The values for $r_{ii}$ are computed, from samples, as the standard deviation of the respective variables ($x_{k}$, $\\dot{x_{k}}$, $y_{k}$, $\\dot{y_{k}}$, $\\theta_{k}$, $\\dot{\\theta_{k}}$).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- From the matrix $\\mathbf{R}$, we compute the model covariance matrix $\\mathbf{Q}$ :\n",
    "\n",
    "$$\n",
    "\\mathbf{Q}\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "q_{11} & 0 & 0 & 0 & 0 & 0 \\\\\n",
    "0 & q_{22} & 0 & 0 & 0 & 0 \\\\\n",
    "0 & 0 & q_{33} & 0 & 0 & 0 \\\\\n",
    "0 & 0 & 0 & q_{44} & 0 & 0 \\\\\n",
    "0 & 0 & 0 & 0 & q_{55} & 0 \\\\\n",
    "0 & 0 & 0 & 0 & 0 & q_{66} \\\\\n",
    "\n",
    "\\end{bmatrix}\\\\\n",
    "$$\n",
    "\n",
    "$\n",
    "q_{11} = q_{cam,x} = 7.73 \\quad\n",
    "q_{22} = q_{\\dot{x}} = 1000\\quad\n",
    "q_{33} = q_{cam,y} = 7.73\\quad\n",
    "q_{44} = q_{\\dot{y}} = 1000\\quad\n",
    "q_{55} = q_{cam,\\theta} = 0.0049\\quad\n",
    "q_{66} = q_{\\dot{\\theta}} = 1000\\quad\n",
    "$\n",
    "\n",
    "The values for $q_{11}$, $q_{33}$ and $q_{55}$ are the same as $r_{11}$, $r_{33}$ and $r_{44}$ because we suppose that the Camera Vision keeps the same error in the model as for the sensors. It gives us the possibility to figure out how wrong the position can become. On the other hand, the values $q_{22}$, $q_{44}$ and $q_{66}$ are set to \"extremely\" high values. This is because the uncertainty of the velocities are high and implies added noise. So, we want that the only way to update the velocities is from the **Odometry**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We compute the matrix that relate the states to the measurements $\\mathbf{H}$ :\n",
    "\n",
    "$$\n",
    "\n",
    "\\mathbf{H_{w/Vision}}\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "1 & 0 & 0 & 0 & 0 & 0 \\\\\n",
    "0 & 1 & 0 & 0 & 0 & 0 \\\\\n",
    "0 & 0 & 1 & 0 & 0 & 0 \\\\\n",
    "0 & 0 & 0 & 1 & 0 & 0 \\\\\n",
    "0 & 0 & 0 & 0 & 1 & 0 \\\\\n",
    "0 & 0 & 0 & 0 & 0 & 1 \\\\\n",
    "\n",
    "\\end{bmatrix}\n",
    "\n",
    "\\hspace{20 mm}\n",
    "\n",
    "\\mathbf{H_{w/outVision}}\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "0 & 1 & 0 & 0 & 0 & 0 \\\\\n",
    "0 & 0 & 0 & 1 & 0 & 0 \\\\\n",
    "0 & 0 & 0 & 0 & 0 & 1 \\\\\n",
    "\n",
    "\\end{bmatrix}\\\\\n",
    "\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Essentially, the best case senario would be to have the imputs from the two sources of sensors, the camera and the wheels' speed. This allows to have as much information available. In this case, the Kalman Filter can compare the two positions and have a more precise estimation. \n",
    "\n",
    "We decided to use as the second source the wheels speed instead of the accelerometer as internal measurements because we assumed it wouldn't be very precise values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>Kalman Filter Function</u>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Funtion | Input | Output |\n",
    "|:------|:------|:------|\n",
    "|   `def filter_kalman(self, X_est_pre, P_est_pre, Thymio) :`  | no function input but uses global variables from the file classes.py and the modified values from the functino **odometry_update** | no real output but updates values for the estimations of the states and the uncertainty, hence, the updated values for the Thymio's position"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Therefore we have two situations to take into account when computing the Kalman Filter equations : when we have simultaneously Computer Vision and Odometry, and when we only have Odometry. \n",
    "\n",
    "In the function **filter_kalman**, an  <span style='color: red;'>if / else</span> condition is implemented to distinguish the 2 cases. When the Computer Vision is functionning, it set a booleen variable **vision** to *true*, so that the code enters in the first case, otherwise, it goes in the second case and uses the matrices set to be used in the situation of pure Odometry.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_kalman(self, Thymio) :\n",
    "     '''code...'''    \n",
    "     if (Thymio.vision) : # If we have the Computer Vision and Odometry\n",
    "\n",
    "          y = [[Thymio.pos_X],[self.v_X],[Thymio.pos_Y],[self.v_Y],[Thymio.theta],[self.v_Theta]] \n",
    "\n",
    "          H = np.eye(6)\n",
    "\n",
    "          R = [[7.73, 0, 0, 0, 0, 0], \n",
    "               [0, 6.48, 0, 0, 0, 0],\n",
    "               [0, 0, 7.73, 0, 0, 0],\n",
    "               [0, 0, 0, 6.48, 0, 0],\n",
    "               [0, 0, 0, 0, 0.0049, 0],\n",
    "               [0, 0, 0, 0, 0, 0.615]]\n",
    "\n",
    "          Thymio.vision = 0\n",
    "     else : # if we only have the Odometry\n",
    "\n",
    "          y = [[self.v_X],[self.v_Y],[self.v_Theta]]\n",
    "\n",
    "          H = [[0, 1, 0, 0, 0, 0],\n",
    "               [0, 0, 0, 1, 0, 0],\n",
    "               [0, 0, 0, 0, 0, 1]]\n",
    "          \n",
    "          R = [[6.48, 0, 0],\n",
    "               [0, 6.48, 0],\n",
    "               [0, 0, 0.615]]\n",
    "     '''...code'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "<u>Odometry</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Odometry allows us to linearize the system so we're able to use the classic Kalman Filter rather than an EKF. Through the equations specified below, we go from a non-linear system with the Thymio wheeel speeds $v_{R}$ and $v_{L}$ to a linear system with cartesian speeds $v_{x}$ and $v_{y}$. The latter speeds are the ones used in the **filter_kalman** function to perform the estimations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Odometry equations\n",
    "\n",
    "$$\n",
    "    \\begin{cases}\n",
    "        v_{x} =\\dot{x} = \\frac{v_{R} + v_{L}}{2} * \\cos\\left (\\theta + \\left (\\frac{\\theta}{2}\\right)\\right) \\\\\n",
    "        \\\\\n",
    "        v_{y} = \\dot{y} =\\frac{v_{R} + v_{L}}{2} * \\sin\\left (\\theta + \\left (\\frac{\\theta}{2}\\right)\\right)\\\\ \n",
    "        \\\\\n",
    "        v_{\\theta} = \\dot{\\theta} = \\frac{v_{R} - v_{L}}{d_{wheels}}\n",
    "    \\end{cases} \n",
    "\n",
    "\n",
    "\\hspace{20 mm}\n",
    "\n",
    "\n",
    "    \\begin{cases}\n",
    "        x_{update} = v_{x} * \\Delta{t}\\\\\n",
    "        \\\\\n",
    "        y_{update} = v_{y} * \\Delta{t}\\\\ \n",
    "        \\\\\n",
    "        \\theta_{update} = v_{\\theta} * \\Delta{t}\n",
    "    \\end{cases} \n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Funtion | Input | Output |\n",
    "|:------|:------|:------|\n",
    "|   `def odometry_update(self, Thymio) :`  | no function input but uses global variables from the file **classes.py** | no real output but modifies values in the class of **KalmanFilter** for the **filter_kalman** function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def odometry_update(self, Thymio) :\n",
    "        '''Odometry calculation'''\n",
    "\n",
    "        self.speed_L = Thymio.motor_speed_left\n",
    "        self.speed_R = Thymio.motor_speed_right\n",
    "        \n",
    "        self.wheel_dist = 9.5 # Distance between the wheel (where they touch the ground)\n",
    "\n",
    "        delta_t = time.time() - pre_time            # time.time() to get the value of the time\n",
    "        delta_S = (self.speed_R + self.speed_L) / 2                         # Forward speed\n",
    "        self.v_Theta =  (self.speed_R - self.speed_L) / self.wheel_dist     # Angular velocity \n",
    "\n",
    "        # calculations of the variations of the speed of the Thymio\n",
    "        self.v_X = delta_S * np.cos(Thymio.theta + self.v_Theta/2)          # SPEED in X\n",
    "        self.v_Y = delta_S * np.sin(Thymio.theta + self.v_Theta/2)          # SPEED in y\n",
    "\n",
    "        # update of the position (coordinates and angle/orientation) of the Thymio after time delta_t\n",
    "        self.pos_X_odo = self.v_X * delta_t\n",
    "        self.pos_Y_odo = self.v_Y * delta_t\n",
    "        self.pos_theta_odo = self.v_Theta * delta_t\n",
    "\n",
    "        # Update for the previous time with the current time for the next iteration\n",
    "        pre_time = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Summary**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In summary, the Kalman Filter seemed to be the best option and the fact that we linearize the system before, using the odometry, we do not need to use the Exteded version even with a non-linear system. \n",
    "\n",
    "We calculated the different parameters for our covariance matrices $\\mathbf{R}$ and $\\mathbf{Q}$ based on measured samples directly taken with the camera and the Thymio's movement.\n",
    "\n",
    "**++impact of the filter on the program, precision etc (illustration avec et sans Kalman et quand camera est cachée)**\n",
    "\n",
    "*The filter has a good impact on the system's precision and we can see that from the illustrations on the camera window. These illustrations come from a function that we deemed interesting to add. It draws ovals with diameters based on the covariance matrice's values in x and y.* \n",
    "\n",
    "*The filter is able to keep an estimation of the position of the robot and correct it, whether the camera is available or not. The prediction is of course more reliable when the camera sends the position of the robot to compute the prediction. We can see that from the oval growing as time passes by when the vision is obstructed.*\n",
    "\n",
    "*Finally, we would say that applying a filter to a small and not so complex system such as the Thymio robot, in an application lasting a few seconds does not have such a impactful influence. However we are now able to understand how important and meaningful to have one on an autonomous system such as a car, a satellite, etc. (basically all linears system with trajectory estimations). During a long-term mission, we cannot expect to cancel the error accumulation, but we can lessen it, hence the usefulness of Bayes filter.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. <a id='toc4_'></a>[VIDEOS ? IMAGES ? LITTLE EXTRAS ?](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. <a id='toc5_'></a>[Overall Project](#toc0_)\n",
    "\n",
    "**do we have to put the main here ? or a code that called our main.py ? to be asked on tuesday maybe**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. <a id='toc6_'></a>[Conclusion](#toc0_)\n",
    "\n",
    "**we need to write a conclusion**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "332.594px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
